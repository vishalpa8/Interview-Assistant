# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2-vision
OLLAMA_VISION_MODEL=llama3.2-vision
OLLAMA_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=0  # 0 = no limit, rely on prompting for response control